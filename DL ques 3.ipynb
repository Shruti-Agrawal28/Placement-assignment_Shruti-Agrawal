{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1045c9",
   "metadata": {},
   "source": [
    "## IMPORTING STATEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b66cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b3f6a",
   "metadata": {},
   "source": [
    "## USING PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866fe5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.2682, Test Accuracy: 96.77%\n",
      "Epoch 2/10, Train Loss: 0.0943, Test Accuracy: 97.14%\n",
      "Epoch 3/10, Train Loss: 0.0724, Test Accuracy: 97.64%\n",
      "Epoch 4/10, Train Loss: 0.0598, Test Accuracy: 97.94%\n",
      "Epoch 5/10, Train Loss: 0.0529, Test Accuracy: 98.20%\n",
      "Epoch 6/10, Train Loss: 0.0453, Test Accuracy: 97.88%\n",
      "Epoch 7/10, Train Loss: 0.0403, Test Accuracy: 98.07%\n",
      "Epoch 8/10, Train Loss: 0.0364, Test Accuracy: 98.12%\n",
      "Epoch 9/10, Train Loss: 0.0334, Test Accuracy: 98.08%\n",
      "Epoch 10/10, Train Loss: 0.0307, Test Accuracy: 97.96%\n"
     ]
    }
   ],
   "source": [
    "# Set the device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the training and testing data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST training and testing datasets\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Set the batch size for training and testing\n",
    "batch_size = 64\n",
    "\n",
    "# Create the data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(14*14*16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss/len(trainloader):.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b86ae",
   "metadata": {},
   "source": [
    "## USING TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3164b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2359424   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,365,514\n",
      "Trainable params: 2,365,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 153s 158ms/step - loss: 0.1303 - accuracy: 0.9605 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 147s 156ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.0341 - val_accuracy: 0.9878\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 146s 156ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.0443 - val_accuracy: 0.9860\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 143s 152ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0437 - val_accuracy: 0.9875\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 146s 156ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0480 - val_accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 134s 143ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0407 - val_accuracy: 0.9886\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 143s 152ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0457 - val_accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 130s 139ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0457 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 137s 146ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0439 - val_accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 133s 142ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0561 - val_accuracy: 0.9865\n",
      "313/313 - 6s - loss: 0.0561 - accuracy: 0.9865 - 6s/epoch - 19ms/step\n",
      "Test Accuracy: 98.65%\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the Pure CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55667cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
